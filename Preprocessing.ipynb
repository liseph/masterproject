{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import reverse_geocoder as rg\n",
    "import preprocessor as p\n",
    "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
    "import math\n",
    "from multiprocessing import  Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Semesteroppgave/datasets/dataset/dataset_twitter/tweetsreplies4.tsv', encoding='cp1252', sep=\"\\t\", usecols=['timestamp_ms','longitude', 'latitude', 'text', 'lang'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Remove rows with missing text, filter out non-english tweets. Get detailed locations and timestamp and tokenize the text.\n",
    "* Fetch more location info from longitude and latitude using reverse_encoder https://github.com/thampiman/reverse-geocoder\n",
    "* Convert ms timestamps to datetime object.\n",
    "* Preprocess text using the preprocessor https://github.com/s/preprocessor and remove stopwords using gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(585341+536) # this row makes the function p.clean crash...\n",
    "df = df.drop(df[df.lang != 'en'].index)\n",
    "df = df.drop(['lang'], axis=1)\n",
    "df = df.drop(df[df.text == ''].index)\n",
    "df = df.drop(df[df.text.isna()].index)\n",
    "df = df.reset_index()\n",
    "df = df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = list(df[['latitude','longitude']].itertuples(index=False, name=None))\n",
    "locations = rg.search(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df = pd.json_normalize(locations)[['name', 'admin1', 'admin2', 'cc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, locations_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func, n_cores=4):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.RESERVED, p.OPT.EMOJI, p.OPT.SMILEY, p.OPT.NUMBER)\n",
    "def add_features(df):\n",
    "    try:\n",
    "        df['text'] = df['text'].apply(p.clean)\n",
    "    except:\n",
    "        print(df['text'])\n",
    "    return df\n",
    "df = parallelize_dataframe(df, add_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lower case and remove numbers and white space, must be done after cleaning\n",
    "df['text']  = df['text'] \\\n",
    "                .str.lower() \\\n",
    "                .str.replace('\\d+', '') \\\n",
    "                .str.replace('a{2,}', 'a') \\\n",
    "                .str.replace('b{3,}', 'b') \\\n",
    "                .str.replace('c{3,}', 'c') \\\n",
    "                .str.replace('d{3,}', 'd') \\\n",
    "                .str.replace('e{3,}', 'e') \\\n",
    "                .str.replace('f{3,}', 'f') \\\n",
    "                .str.replace('g{3,}', 'g') \\\n",
    "                .str.replace('h{3,}', 'h') \\\n",
    "                .str.replace('i{2,}', 'i') \\\n",
    "                .str.replace('j{3,}', 'j') \\\n",
    "                .str.replace('k{3,}', 'k') \\\n",
    "                .str.replace('l{3,}', 'l') \\\n",
    "                .str.replace('m{3,}', 'm') \\\n",
    "                .str.replace('n{3,}', 'n') \\\n",
    "                .str.replace('o{3,}', 'o') \\\n",
    "                .str.replace('p{3,}', 'p') \\\n",
    "                .str.replace('q{3,}', 'q') \\\n",
    "                .str.replace('r{3,}', 'r') \\\n",
    "                .str.replace('s{3,}', 's') \\\n",
    "                .str.replace('t{3,}', 't') \\\n",
    "                .str.replace('u{2,}', 'u') \\\n",
    "                .str.replace('v{3,}', 'v') \\\n",
    "                .str.replace('w{3,}', 'w') \\\n",
    "                .str.replace('x{3,}', 'x') \\\n",
    "                .str.replace('y{2,}', 'y') \\\n",
    "                .str.replace('z{3,}', 'z') \\\n",
    "                .str.replace('_', ' ') \\\n",
    "                .str.replace(' rt ', '') \\\n",
    "                .str.replace('#', '') \\\n",
    "                .str.replace('[^\\w\\s]',' ') \\\n",
    "                .str.replace('\\s\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords, must be done after cleaning and removal of white space\n",
    "def remove_stopwords_f(df):\n",
    "    df['text'] = df['text'].apply(remove_stopwords)\n",
    "    return df\n",
    "df = parallelize_dataframe(df, remove_stopwords_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df.text == ''].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['timestamp_ms', 'admin1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['admin2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "      <th>admin1</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1443887442007</td>\n",
       "      <td>-66.578926</td>\n",
       "      <td>6.422820</td>\n",
       "      <td>yo quiero que sea mi sponsor zayn malik goals ...</td>\n",
       "      <td>Puerto Carreno</td>\n",
       "      <td>Vichada</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1443887443914</td>\n",
       "      <td>-73.948775</td>\n",
       "      <td>40.655138</td>\n",
       "      <td>confirmed justin bieber incredibly dumb</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1443887501098</td>\n",
       "      <td>-122.228685</td>\n",
       "      <td>37.791994</td>\n",
       "      <td>s true</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1443887588840</td>\n",
       "      <td>-122.630908</td>\n",
       "      <td>45.536402</td>\n",
       "      <td>going taco bell absolutely makes taco</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1443888128338</td>\n",
       "      <td>21.060742</td>\n",
       "      <td>52.232836</td>\n",
       "      <td>ofc</td>\n",
       "      <td>Praga Poludnie</td>\n",
       "      <td>Masovian Voivodeship</td>\n",
       "      <td>PL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>1443916393180</td>\n",
       "      <td>-79.272569</td>\n",
       "      <td>43.629311</td>\n",
       "      <td>tourtoronto tweeryourseat kidding sec row seats</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>1443916421554</td>\n",
       "      <td>-60.029848</td>\n",
       "      <td>-37.147576</td>\n",
       "      <td>s oh quiet emabiggestfansjustinbieber</td>\n",
       "      <td>Olavarria</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1443916429182</td>\n",
       "      <td>-43.441578</td>\n",
       "      <td>-22.911422</td>\n",
       "      <td>cem rts cem vote pelo justin iwannahearwdymons...</td>\n",
       "      <td>Nilopolis</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>1443916444910</td>\n",
       "      <td>-60.029848</td>\n",
       "      <td>-37.147576</td>\n",
       "      <td>u emabiggestfansjustinbieber</td>\n",
       "      <td>Olavarria</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>1443916455181</td>\n",
       "      <td>-89.569491</td>\n",
       "      <td>44.900802</td>\n",
       "      <td>jeremy youre good kid wouldve touched thing</td>\n",
       "      <td>Weston</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp_ms   longitude   latitude  \\\n",
       "1     1443887442007  -66.578926   6.422820   \n",
       "5     1443887443914  -73.948775  40.655138   \n",
       "2     1443887501098 -122.228685  37.791994   \n",
       "4     1443887588840 -122.630908  45.536402   \n",
       "7     1443888128338   21.060742  52.232836   \n",
       "...             ...         ...        ...   \n",
       "1334  1443916393180  -79.272569  43.629311   \n",
       "529   1443916421554  -60.029848 -37.147576   \n",
       "1305  1443916429182  -43.441578 -22.911422   \n",
       "726   1443916444910  -60.029848 -37.147576   \n",
       "1315  1443916455181  -89.569491  44.900802   \n",
       "\n",
       "                                                   text            name  \\\n",
       "1     yo quiero que sea mi sponsor zayn malik goals ...  Puerto Carreno   \n",
       "5               confirmed justin bieber incredibly dumb        Brooklyn   \n",
       "2                                                s true         Alameda   \n",
       "4                 going taco bell absolutely makes taco        Portland   \n",
       "7                                                   ofc  Praga Poludnie   \n",
       "...                                                 ...             ...   \n",
       "1334    tourtoronto tweeryourseat kidding sec row seats     Scarborough   \n",
       "529               s oh quiet emabiggestfansjustinbieber       Olavarria   \n",
       "1305  cem rts cem vote pelo justin iwannahearwdymons...       Nilopolis   \n",
       "726                        u emabiggestfansjustinbieber       Olavarria   \n",
       "1315        jeremy youre good kid wouldve touched thing          Weston   \n",
       "\n",
       "                    admin1  cc  \n",
       "1                  Vichada  CO  \n",
       "5                 New York  US  \n",
       "2               California  US  \n",
       "4                   Oregon  US  \n",
       "7     Masovian Voivodeship  PL  \n",
       "...                    ...  ..  \n",
       "1334               Ontario  CA  \n",
       "529           Buenos Aires  AR  \n",
       "1305        Rio de Janeiro  BR  \n",
       "726           Buenos Aires  AR  \n",
       "1315             Wisconsin  US  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.head(1000)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = '%d\\n%.8f\\n%.8f\\n%s\\n%s\\n%s\\n%s'\n",
    "#np.savetxt(r'dataset5000En.txt', df.values, fmt=fmt, delimiter='\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = '%d\\n%.8f\\n%.8f\\n%s\\n%s\\n%s\\n%s'\n",
    "df.to_csv(r'dataset1000En.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#what is FAV00 RT _'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.clean(\"#what is https://vg.no @me FAV00 00 RT _\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
