{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import reverse_geocoder as rg\n",
    "import preprocessor as p\n",
    "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
    "import math\n",
    "from multiprocessing import  Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Semesteroppgave/datasets/dataset/dataset_twitter/tweetsreplies4.tsv', encoding='cp1252', sep=\"\\t\", usecols=['timestamp_ms','longitude', 'latitude', 'text', 'lang'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Remove rows with missing text, filter out non-english tweets. Get detailed locations and timestamp and tokenize the text.\n",
    "* Fetch more location info from longitude and latitude using reverse_encoder https://github.com/thampiman/reverse-geocoder\n",
    "* Convert ms timestamps to datetime object.\n",
    "* Preprocess text using the preprocessor https://github.com/s/preprocessor and remove stopwords using gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(585341+536) # this row makes the function p.clean crash...\n",
    "df = df.drop(df[df.lang != 'en'].index)\n",
    "df = df.drop(['lang'], axis=1)\n",
    "df = df.drop(df[df.text == ''].index)\n",
    "df = df.drop(df[df.text.isna()].index)\n",
    "df = df.reset_index()\n",
    "df = df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = list(df[['latitude','longitude']].itertuples(index=False, name=None))\n",
    "locations = rg.search(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df = pd.json_normalize(locations)[['name', 'admin1', 'admin2', 'cc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, locations_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func, n_cores=4):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.RESERVED, p.OPT.EMOJI, p.OPT.SMILEY, p.OPT.NUMBER)\n",
    "def add_features(df):\n",
    "    try:\n",
    "        df['text'] = df['text'].apply(p.clean)\n",
    "    except:\n",
    "        print(df['text'])\n",
    "    return df\n",
    "df = parallelize_dataframe(df, add_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lower case and remove numbers and white space, must be done after cleaning\n",
    "df['text']  = df['text'] \\\n",
    "                .str.lower() \\\n",
    "                .str.replace('\\d+', '') \\\n",
    "                .str.replace('a{2,}', 'a') \\\n",
    "                .str.replace('b{3,}', 'b') \\\n",
    "                .str.replace('c{3,}', 'c') \\\n",
    "                .str.replace('d{3,}', 'd') \\\n",
    "                .str.replace('e{3,}', 'e') \\\n",
    "                .str.replace('f{3,}', 'f') \\\n",
    "                .str.replace('g{3,}', 'g') \\\n",
    "                .str.replace('h{3,}', 'h') \\\n",
    "                .str.replace('i{2,}', 'i') \\\n",
    "                .str.replace('j{3,}', 'j') \\\n",
    "                .str.replace('k{3,}', 'k') \\\n",
    "                .str.replace('l{3,}', 'l') \\\n",
    "                .str.replace('m{3,}', 'm') \\\n",
    "                .str.replace('n{3,}', 'n') \\\n",
    "                .str.replace('o{3,}', 'o') \\\n",
    "                .str.replace('p{3,}', 'p') \\\n",
    "                .str.replace('q{3,}', 'q') \\\n",
    "                .str.replace('r{3,}', 'r') \\\n",
    "                .str.replace('s{3,}', 's') \\\n",
    "                .str.replace('t{3,}', 't') \\\n",
    "                .str.replace('u{2,}', 'u') \\\n",
    "                .str.replace('v{3,}', 'v') \\\n",
    "                .str.replace('w{3,}', 'w') \\\n",
    "                .str.replace('x{3,}', 'x') \\\n",
    "                .str.replace('y{2,}', 'y') \\\n",
    "                .str.replace('z{3,}', 'z') \\\n",
    "                .str.replace('_', ' ') \\\n",
    "                .str.replace(' rt ', '') \\\n",
    "                .str.replace('#', '') \\\n",
    "                .str.replace('[^\\w\\s]',' ') \\\n",
    "                .str.replace('\\s\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords, must be done after cleaning and removal of white space\n",
    "def remove_stopwords_f(df):\n",
    "    df['text'] = df['text'].apply(remove_stopwords)\n",
    "    return df\n",
    "df = parallelize_dataframe(df, remove_stopwords_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df.text == ''].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['timestamp_ms', 'admin1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['admin2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "      <th>admin1</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1443887442007</td>\n",
       "      <td>-66.578926</td>\n",
       "      <td>6.422820</td>\n",
       "      <td>yo quiero que sea mi sponsor zayn malik goals ...</td>\n",
       "      <td>Puerto Carreno</td>\n",
       "      <td>Vichada</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1443887443914</td>\n",
       "      <td>-73.948775</td>\n",
       "      <td>40.655138</td>\n",
       "      <td>confirmed justin bieber incredibly dumb</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1443887501098</td>\n",
       "      <td>-122.228685</td>\n",
       "      <td>37.791994</td>\n",
       "      <td>s true</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1443887588840</td>\n",
       "      <td>-122.630908</td>\n",
       "      <td>45.536402</td>\n",
       "      <td>going taco bell absolutely makes taco</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1443888128338</td>\n",
       "      <td>21.060742</td>\n",
       "      <td>52.232836</td>\n",
       "      <td>ofc</td>\n",
       "      <td>Praga Poludnie</td>\n",
       "      <td>Masovian Voivodeship</td>\n",
       "      <td>PL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125751</th>\n",
       "      <td>1570990637468</td>\n",
       "      <td>-5.151340</td>\n",
       "      <td>50.337553</td>\n",
       "      <td>yes love</td>\n",
       "      <td>Perranporth</td>\n",
       "      <td>England</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164505</th>\n",
       "      <td>1572644823143</td>\n",
       "      <td>-96.331528</td>\n",
       "      <td>32.975669</td>\n",
       "      <td>loves magic ent roysecity</td>\n",
       "      <td>Royse City</td>\n",
       "      <td>Texas</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147357</th>\n",
       "      <td>1573156915209</td>\n",
       "      <td>-38.519890</td>\n",
       "      <td>-3.789768</td>\n",
       "      <td>megan happened interview cnn amanp</td>\n",
       "      <td>Fortaleza</td>\n",
       "      <td>Ceara</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105097</th>\n",
       "      <td>1575247560716</td>\n",
       "      <td>-80.476404</td>\n",
       "      <td>43.430240</td>\n",
       "      <td>radio stationi listen everyday turns day every...</td>\n",
       "      <td>Kitchener</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150799</th>\n",
       "      <td>1575380994602</td>\n",
       "      <td>-77.014398</td>\n",
       "      <td>38.898603</td>\n",
       "      <td>bladee whitearmor bangs</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257398 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp_ms   longitude   latitude  \\\n",
       "1       1443887442007  -66.578926   6.422820   \n",
       "5       1443887443914  -73.948775  40.655138   \n",
       "2       1443887501098 -122.228685  37.791994   \n",
       "4       1443887588840 -122.630908  45.536402   \n",
       "7       1443888128338   21.060742  52.232836   \n",
       "...               ...         ...        ...   \n",
       "125751  1570990637468   -5.151340  50.337553   \n",
       "164505  1572644823143  -96.331528  32.975669   \n",
       "147357  1573156915209  -38.519890  -3.789768   \n",
       "105097  1575247560716  -80.476404  43.430240   \n",
       "150799  1575380994602  -77.014398  38.898603   \n",
       "\n",
       "                                                     text              name  \\\n",
       "1       yo quiero que sea mi sponsor zayn malik goals ...    Puerto Carreno   \n",
       "5                 confirmed justin bieber incredibly dumb          Brooklyn   \n",
       "2                                                  s true           Alameda   \n",
       "4                   going taco bell absolutely makes taco          Portland   \n",
       "7                                                     ofc    Praga Poludnie   \n",
       "...                                                   ...               ...   \n",
       "125751                                           yes love       Perranporth   \n",
       "164505                          loves magic ent roysecity        Royse City   \n",
       "147357                 megan happened interview cnn amanp         Fortaleza   \n",
       "105097  radio stationi listen everyday turns day every...         Kitchener   \n",
       "150799                            bladee whitearmor bangs  Washington, D.C.   \n",
       "\n",
       "                      admin1  cc  \n",
       "1                    Vichada  CO  \n",
       "5                   New York  US  \n",
       "2                 California  US  \n",
       "4                     Oregon  US  \n",
       "7       Masovian Voivodeship  PL  \n",
       "...                      ...  ..  \n",
       "125751               England  GB  \n",
       "164505                 Texas  US  \n",
       "147357                 Ceara  BR  \n",
       "105097               Ontario  CA  \n",
       "150799      Washington, D.C.  US  \n",
       "\n",
       "[257398 rows x 7 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = '%d\\n%.8f\\n%.8f\\n%s\\n%s\\n%s\\n%s'\n",
    "np.savetxt(r'datasetAllEn.txt', df.values, fmt=fmt, delimiter='\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#what is FAV00 RT _'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.clean(\"#what is https://vg.no @me FAV00 00 RT _\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
